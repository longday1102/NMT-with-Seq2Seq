{"cells":[{"cell_type":"markdown","metadata":{},"source":["* ### **Install library**                                  \n"," **Note:**  I use MosesTokenizer for the task of separating words in sentences "]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:57:39.766865Z","iopub.status.busy":"2023-02-16T11:57:39.766518Z","iopub.status.idle":"2023-02-16T11:57:58.671599Z","shell.execute_reply":"2023-02-16T11:57:58.670416Z","shell.execute_reply.started":"2023-02-16T11:57:39.766786Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting mosestokenizer\n","  Downloading mosestokenizer-1.2.1.tar.gz (37 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: docopt in /opt/conda/lib/python3.7/site-packages (from mosestokenizer) (0.6.2)\n","Collecting openfile\n","  Downloading openfile-0.0.7-py3-none-any.whl (2.4 kB)\n","Collecting uctools\n","  Downloading uctools-1.3.0.tar.gz (4.6 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting toolwrapper\n","  Downloading toolwrapper-2.1.0.tar.gz (3.2 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hBuilding wheels for collected packages: mosestokenizer, toolwrapper, uctools\n","  Building wheel for mosestokenizer (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for mosestokenizer: filename=mosestokenizer-1.2.1-py3-none-any.whl size=49189 sha256=4a27c10d36168e6be5932feaa135ebf5cb0c6b345d8f0f562b1050fd4ae71309\n","  Stored in directory: /root/.cache/pip/wheels/b0/35/f7/af1258779a0b890abc3c79481460c597cb1f3659d0603cfb9d\n","  Building wheel for toolwrapper (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for toolwrapper: filename=toolwrapper-2.1.0-py3-none-any.whl size=3353 sha256=d4ae5b015957f9e24d1bab5bfb2f17d791c062b104de9ef87717df55c1efb2f7\n","  Stored in directory: /root/.cache/pip/wheels/c5/4f/33/54741ffe08e38ececb1d28068a153729b4fe820bafa0a0691f\n","  Building wheel for uctools (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for uctools: filename=uctools-1.3.0-py3-none-any.whl size=6161 sha256=1730c1daa0d3019990c5c089c0dd5d0788760a8155b1efde27d06417c943ffda\n","  Stored in directory: /root/.cache/pip/wheels/fb/44/e9/914cf8fa71f0141f9314f862538d1218fcf2b94542a0fb7d35\n","Successfully built mosestokenizer toolwrapper uctools\n","Installing collected packages: toolwrapper, openfile, uctools, mosestokenizer\n","Successfully installed mosestokenizer-1.2.1 openfile-0.0.7 toolwrapper-2.1.0 uctools-1.3.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install mosestokenizer"]},{"cell_type":"markdown","metadata":{},"source":["* ### **Display GPU configuaration**"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:57:58.676083Z","iopub.status.busy":"2023-02-16T11:57:58.675762Z","iopub.status.idle":"2023-02-16T11:57:58.766673Z","shell.execute_reply":"2023-02-16T11:57:58.764825Z","shell.execute_reply.started":"2023-02-16T11:57:58.676054Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Feb 16 11:57:58 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   29C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","    print('Not connected to a GPU')\n","else:\n","    print(gpu_info)"]},{"cell_type":"markdown","metadata":{},"source":["* ### **Import library**"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:57:58.772650Z","iopub.status.busy":"2023-02-16T11:57:58.768733Z","iopub.status.idle":"2023-02-16T11:58:04.311810Z","shell.execute_reply":"2023-02-16T11:58:04.310810Z","shell.execute_reply.started":"2023-02-16T11:57:58.772604Z"},"trusted":true},"outputs":[],"source":["from mosestokenizer import MosesTokenizer\n","from tqdm import tqdm\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.layers import LSTM, Embedding, Dense, Bidirectional\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","from nltk.translate.bleu_score import SmoothingFunction, corpus_bleu\n","from collections import Counter\n","import time"]},{"cell_type":"markdown","metadata":{},"source":["* ### **Setting parameters, hyper-parameters for the model**"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:58:04.315584Z","iopub.status.busy":"2023-02-16T11:58:04.314335Z","iopub.status.idle":"2023-02-16T11:58:04.327682Z","shell.execute_reply":"2023-02-16T11:58:04.326491Z","shell.execute_reply.started":"2023-02-16T11:58:04.315541Z"},"trusted":true},"outputs":[],"source":["class Config:\n","    def __init__(self,\n","               min_len = 0,\n","               max_len = 50,\n","               batch_size = 256,\n","               embedding_size = 512,\n","               hidden_units = 512,\n","               epochs = 20,\n","               learning_rate = 0.0008,\n","               dropout = 0.2,\n","               start_token = '<sos>',\n","               end_token = '<eos>',\n","               pad_token = '<pad>',\n","               unk_token = '<unk>',\n","               lang_1 = 'en',\n","               lang_2 = 'vi'):\n","        \n","        self.min_len = min_len\n","        self.max_len = max_len\n","        self.batch_size = batch_size\n","        self.embedding_size = embedding_size\n","        self.hidden_units = hidden_units\n","        self.epochs = epochs\n","        self.learning_rate = learning_rate\n","        self.dropout = dropout\n","        self.start_token = start_token\n","        self.end_token = end_token\n","        self.pad_token = pad_token\n","        self.unk_token = unk_token\n","        self.LANG_1 = lang_1\n","        self.LANG_2 = lang_2"]},{"cell_type":"markdown","metadata":{},"source":["* ### **Data processing and Dataloader**                                     \n","    **Note:**  The classes from **Vocabulary** to **Dataloader** are used for input data processing and dataloader creation"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:58:04.330046Z","iopub.status.busy":"2023-02-16T11:58:04.329342Z","iopub.status.idle":"2023-02-16T11:58:04.350438Z","shell.execute_reply":"2023-02-16T11:58:04.349485Z","shell.execute_reply.started":"2023-02-16T11:58:04.330000Z"},"trusted":true},"outputs":[],"source":["class Vocabulary:    \n","    def __init__(self,               \n","                 config,\n","                 data_path,\n","                 frequency,\n","                 lang,\n","                 add_sos,\n","                 add_eos,\n","                 add_pad,\n","                 add_unk):\n","        self.config = config\n","        self.data_path = data_path\n","        self.tokenizer = MosesTokenizer(lang)\n","        self.counter = Counter()\n","        self.frequency = frequency\n","        self.add_sos = add_sos\n","        self.add_eos = add_eos\n","        self.add_pad = add_pad\n","        self.add_unk = add_unk\n","\n","    def word2idx(self):\n","        word2idx = {}\n","        with open(self.data_path, encoding = 'utf-8', mode = 'r') as f:          \n","            for line in f:\n","                self.counter.update(self.tokenizer(line))\n","\n","        if self.add_pad:\n","            word2idx[self.config.pad_token] = len(word2idx)\n","        if self.add_unk:\n","            word2idx[self.config.unk_token] = len(word2idx)\n","        if self.add_sos:\n","            word2idx[self.config.start_token] = len(word2idx)\n","        if self.add_eos:\n","            word2idx[self.config.end_token] = len(word2idx)\n","    \n","        for word, freq in self.counter.items():\n","            if freq >= self.frequency:\n","                word2idx[word] = len(word2idx)\n","\n","        return word2idx"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:58:04.352547Z","iopub.status.busy":"2023-02-16T11:58:04.351799Z","iopub.status.idle":"2023-02-16T11:58:04.362806Z","shell.execute_reply":"2023-02-16T11:58:04.361812Z","shell.execute_reply.started":"2023-02-16T11:58:04.352510Z"},"trusted":true},"outputs":[],"source":["class Language:\n","    def __init__(self,\n","                 config,\n","                 lang,\n","                 word2idx,\n","                 idx2word):\n","        self.config = config\n","        self.tokenizer = MosesTokenizer(lang)\n","        self.word2idx = word2idx\n","        self.idx2word = idx2word\n","  \n","    def encode(self, sentence):\n","        sequence = []\n","        for word in self.tokenizer(sentence):\n","            if word in self.word2idx:\n","                sequence.append(self.word2idx[word])\n","            else:\n","                sequence.append(self.word2idx[self.config.unk_token])\n","        return sequence\n","\n","    def add_border(self, sequence):\n","        return [self.word2idx[self.config.start_token]] + sequence + [self.word2idx[self.config.end_token]]\n","\n","    def decode(self, sequence):\n","        sentence = [self.idx2word[idx] for idx in sequence]\n","        sentence = \" \".join(sentence)\n","        return sentence"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:58:04.365077Z","iopub.status.busy":"2023-02-16T11:58:04.364392Z","iopub.status.idle":"2023-02-16T11:58:41.196228Z","shell.execute_reply":"2023-02-16T11:58:41.194577Z","shell.execute_reply.started":"2023-02-16T11:58:04.365043Z"},"trusted":true},"outputs":[],"source":["en_train_file_path = '/kaggle/input/mt-en-vi/src-train.txt'\n","vi_train_file_path = '/kaggle/input/mt-en-vi/tgt-train.txt'\n","en_val_file_path = '/kaggle/input/mt-en-vi/src-val.txt'\n","vi_val_file_path = '/kaggle/input/mt-en-vi/tgt-val.txt'\n","en_test_file_path = '/kaggle/input/mt-en-vi/src-test.txt'\n","vi_test_file_path = '/kaggle/input/mt-en-vi/tgt-test.txt'\n","\n","source_add = {'add_sos': True,\n","              'add_eos': True,\n","              'add_pad': True,\n","              'add_unk': True}\n","target_add = {'add_sos': True,\n","              'add_eos': True,\n","              'add_pad': True,\n","              'add_unk': True}\n","\n","frequency = 5\n","config = Config()\n","\n","source_vocab = Vocabulary(config,\n","                          en_train_file_path,\n","                          frequency,\n","                          config.LANG_1,\n","                          source_add['add_sos'],\n","                          source_add['add_eos'],\n","                          source_add['add_pad'],\n","                          source_add['add_unk'])\n","target_vocab = Vocabulary(config,\n","                          vi_train_file_path,\n","                          frequency,\n","                          config.LANG_2,\n","                          target_add['add_sos'],\n","                          target_add['add_eos'],\n","                          target_add['add_pad'],\n","                          target_add['add_unk'])\n","\n","source_word2idx = source_vocab.word2idx()\n","target_word2idx = target_vocab.word2idx()\n","source_idx2word = {value: key for key, value in source_word2idx.items()}\n","target_idx2word = {value: key for key, value in target_word2idx.items()}\n","\n","source_lang = Language(config,\n","                       config.LANG_1,\n","                       source_word2idx,\n","                       source_idx2word)\n","target_lang = Language(config,\n","                       config.LANG_2,\n","                       target_word2idx,\n","                       target_idx2word)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:58:41.198827Z","iopub.status.busy":"2023-02-16T11:58:41.198450Z","iopub.status.idle":"2023-02-16T11:58:41.217899Z","shell.execute_reply":"2023-02-16T11:58:41.216334Z","shell.execute_reply.started":"2023-02-16T11:58:41.198787Z"},"trusted":true},"outputs":[],"source":["class Lang_utils:\n","    def __init__(self,\n","               word2idx,\n","               idx2word,\n","               lang,\n","               train_path,\n","               val_path,\n","               test_path):\n","        self.word_index = word2idx\n","        self.index_word = idx2word\n","        self.encode = lang.encode\n","        self.add_border = lang.add_border\n","        self.decode = lang.decode\n","        self.train_path = train_path\n","        self.val_path = val_path \n","        self.test_path = test_path\n","\n","en_utils = Lang_utils(source_word2idx,\n","                      source_idx2word,\n","                      source_lang,\n","                      en_train_file_path,\n","                      en_val_file_path,\n","                      en_test_file_path)\n","\n","vi_utils = Lang_utils(target_word2idx,\n","                      target_idx2word,\n","                      target_lang,\n","                      vi_train_file_path,\n","                      vi_val_file_path,\n","                      vi_test_file_path)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:58:41.220943Z","iopub.status.busy":"2023-02-16T11:58:41.220354Z","iopub.status.idle":"2023-02-16T11:58:41.266663Z","shell.execute_reply":"2023-02-16T11:58:41.265703Z","shell.execute_reply.started":"2023-02-16T11:58:41.220904Z"},"trusted":true},"outputs":[],"source":["class Dataloader:\n","    def __init__(self,\n","               en_utils,\n","               vi_utils,\n","               config):\n","        self.en_utils = en_utils\n","        self.vi_utils = vi_utils\n","        self.config = config\n","        self.train_process_en = []\n","        self.train_process_vi = []\n","        self.val_process_en = []\n","        self.val_process_vi = []\n","        self.test_process_en = []\n","        self.test_process_vi = []\n","\n","    def read_data(self, path):\n","        with open(path, encoding = 'utf-8', mode = 'r') as f:\n","            file_opened = f.read().strip().split('\\n')\n","        return file_opened\n","    \n","    def process_long_sequence(self, seq_1, seq_2):\n","        list_seq_1 = [seq_1[i: i + self.config.max_len] for i in range(0, len(seq_1), self.config.max_len)]\n","        list_seq_2 = [seq_2[i: i + self.config.max_len] for i in range(0, len(seq_2), self.config.max_len)]\n","        if len(list_seq_1) > len(list_seq_2):\n","            list_seq_1 = list_seq_1[:len(list_seq_2)]\n","        else:\n","            list_seq_2 = list_seq_2[:len(list_seq_1)]\n","\n","        assert len(list_seq_1) == len(list_seq_2), \"Length difference between 2 list\"\n","        return list_seq_1, list_seq_2\n","            \n","    def padding(self, seq_batch, lang_utils):\n","        max_len = max([len(seq) for seq in seq_batch])\n","        for i in range(len(seq_batch)):\n","            seq = seq_batch[i]\n","            seq += [lang_utils.word_index[self.config.pad_token]]*(max_len - len(seq))\n","            seq_batch[i] = seq\n","        return seq_batch\n","\n","    def texts_to_sequences(self, list_texts, lang_utils):\n","        for i in range(len(list_texts)):\n","            list_texts[i] = lang_utils.encode(list_texts[i])\n","        return list_texts\n","\n","    def dataset(self):\n","        src_train_lang = self.read_data(self.en_utils.train_path)\n","        src_val_lang = self.read_data(self.en_utils.val_path)\n","        src_test_lang = self.read_data(self.en_utils.test_path)\n","        tgt_train_lang = self.read_data(self.vi_utils.train_path)\n","        tgt_val_lang = self.read_data(self.vi_utils.val_path)\n","        tgt_test_lang = self.read_data(self.vi_utils.test_path)\n","\n","        seq_src_train = self.texts_to_sequences(src_train_lang, self.en_utils)\n","        seq_src_val = self.texts_to_sequences(src_val_lang, self.en_utils)\n","        seq_src_test = self.texts_to_sequences(src_test_lang, self.en_utils)\n","        seq_tgt_train = self.texts_to_sequences(tgt_train_lang, self.vi_utils)\n","        seq_tgt_val = self.texts_to_sequences(tgt_val_lang, self.vi_utils)\n","        seq_tgt_test = self.texts_to_sequences(tgt_test_lang, self.vi_utils)\n","\n","        for en_seq, vi_seq in zip(seq_src_train, seq_tgt_train):  \n","            if self.config.min_len < len(en_seq) < self.config.max_len and self.config.min_len < len(vi_seq) < self.config.max_len:    \n","                self.train_process_en.append(self.en_utils.add_border(en_seq))\n","                self.train_process_vi.append(self.vi_utils.add_border(vi_seq))\n","            else:\n","                cut_en_seq, cut_vi_seq = self.process_long_sequence(en_seq, vi_seq)\n","                for en_gram, vi_gram in zip(cut_en_seq, cut_vi_seq):\n","                    self.train_process_en.append(self.en_utils.add_border(en_gram))\n","                    self.train_process_vi.append(self.vi_utils.add_border(vi_gram))\n","  \n","        assert len(self.train_process_en) == len(self.train_process_vi), \"The size of the 2 training sets is not equal\"\n","    \n","        for en_seq, vi_seq in zip(seq_src_val, seq_tgt_val):\n","            if self.config.min_len < len(en_seq) < self.config.max_len and self.config.min_len < len(vi_seq) < self.config.max_len:\n","                self.val_process_en.append(self.en_utils.add_border(en_seq))\n","                self.val_process_vi.append(self.vi_utils.add_border(vi_seq))\n","            else:\n","                cut_en_seq, cut_vi_seq = self.process_long_sequence(en_seq, vi_seq)\n","                for en_gram, vi_gram in zip(cut_en_seq, cut_vi_seq):\n","                    self.val_process_en.append(self.en_utils.add_border(en_gram))\n","                    self.val_process_vi.append(self.vi_utils.add_border(vi_gram))\n","\n","        assert len(self.val_process_en) == len(self.val_process_vi), \"The size of the 2 validation sets is not equal\"\n","        \n","        for en_seq, vi_seq in zip(seq_src_test, seq_tgt_test):\n","            if self.config.min_len < len(en_seq) < self.config.max_len and self.config.min_len < len(vi_seq) < self.config.max_len:\n","                self.test_process_en.append(self.en_utils.add_border(en_seq))\n","                self.test_process_vi.append(self.vi_utils.add_border(vi_seq))\n","            else:\n","                cut_en_seq, cut_vi_seq = self.process_long_sequence(en_seq, vi_seq)\n","                for en_gram, vi_gram in zip(cut_en_seq, cut_vi_seq):\n","                    self.test_process_en.append(self.en_utils.add_border(en_gram))\n","                    self.test_process_vi.append(self.vi_utils.add_border(vi_gram))\n","                    \n","        assert len(self.test_process_en) == len(self.test_process_vi), \"The size of the 2 testing sets is not equal\"\n","\n","        X_train = tf.convert_to_tensor(self.padding(self.train_process_en, self.en_utils))\n","        Y_train = tf.convert_to_tensor(self.padding(self.train_process_vi, self.vi_utils))\n","        X_val = tf.convert_to_tensor(self.padding(self.val_process_en, self.en_utils))\n","        Y_val = tf.convert_to_tensor(self.padding(self.val_process_vi, self.vi_utils))\n","        X_test = tf.convert_to_tensor(self.padding(self.test_process_en, self.en_utils))\n","        Y_test = tf.convert_to_tensor(self.padding(self.test_process_vi, self.vi_utils))\n","    \n","        print('Shape of train source tensor: ', X_train.shape)\n","        print('Shape of train target tensor: ', Y_train.shape)\n","        print('Shape of val source tensor: ', X_val.shape)\n","        print('Shape of val target tensor: ', Y_val.shape)\n","        print('Shape of test source tensor: ', X_test.shape)\n","        print('Shape of test target tensor: ', Y_test.shape)\n","\n","        train_ds = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(self.config.batch_size)\n","        val_ds = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n","        test_ds = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n","        \n","        print('Batch number of training set: ', len(train_ds))\n","        return train_ds, val_ds, test_ds"]},{"cell_type":"markdown","metadata":{},"source":["* ### **Encoder block**                                       "]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:58:41.271976Z","iopub.status.busy":"2023-02-16T11:58:41.271399Z","iopub.status.idle":"2023-02-16T11:58:41.280396Z","shell.execute_reply":"2023-02-16T11:58:41.279681Z","shell.execute_reply.started":"2023-02-16T11:58:41.271935Z"},"trusted":true},"outputs":[],"source":["class Encoder(tf.keras.Model):\n","    def __init__(self, config, en_vocab_size):\n","        super(Encoder, self).__init__()\n","        self.Embedding = Embedding(en_vocab_size,\n","                                  config.embedding_size)\n","        self.Bi_LSTM = Bidirectional(LSTM(config.hidden_units,\n","                                            return_sequences = True,\n","                                            return_state = True,\n","                                            dropout = config.dropout),\n","                                       merge_mode = 'sum')\n","        \n","    def __call__(self, x):\n","        enc_embedding = self.Embedding(x)\n","        enc_outputs, fw_h, fw_c, bw_h, bw_c = self.Bi_LSTM(enc_embedding)\n","        state_h = fw_h + bw_h\n","        state_c = fw_c + bw_c\n","        enc_states = [[state_h, state_c], [state_h, state_c]]\n","        return enc_outputs, enc_states"]},{"cell_type":"markdown","metadata":{},"source":["* ### **Luong's attention layer**"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:58:41.282394Z","iopub.status.busy":"2023-02-16T11:58:41.281816Z","iopub.status.idle":"2023-02-16T11:58:41.292496Z","shell.execute_reply":"2023-02-16T11:58:41.291571Z","shell.execute_reply.started":"2023-02-16T11:58:41.282358Z"},"trusted":true},"outputs":[],"source":["class Luong_Attention(tf.keras.layers.Layer):\n","    def __init__(self, config):\n","        super(Luong_Attention, self).__init__()\n","        self.Wa = Dense(config.hidden_units)\n","        \n","    def __call__(self, enc_outputs, dec_outputs):\n","        score = tf.matmul(dec_outputs, self.Wa(enc_outputs), transpose_b = True)\n","        alignment = tf.nn.softmax(score, axis = 2)\n","        context = tf.matmul(alignment, enc_outputs)\n","        return context, score"]},{"cell_type":"markdown","metadata":{},"source":["* ### **Decoder block**"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:58:41.296083Z","iopub.status.busy":"2023-02-16T11:58:41.295810Z","iopub.status.idle":"2023-02-16T11:58:41.307089Z","shell.execute_reply":"2023-02-16T11:58:41.306150Z","shell.execute_reply.started":"2023-02-16T11:58:41.296058Z"},"trusted":true},"outputs":[],"source":["class Decoder(tf.keras.Model):\n","    def __init__(self, config, attention, vi_vocab_size):\n","        super(Decoder, self).__init__()\n","        self.Embedding = Embedding(vi_vocab_size,\n","                                  config.embedding_size)\n","        self.LSTM_1 = LSTM(config.hidden_units,\n","                          dropout = config.dropout,\n","                          return_sequences = True,\n","                          return_state = True)\n","        self.LSTM_2 = LSTM(config.hidden_units,\n","                          dropout = config.dropout,\n","                          return_sequences = True,\n","                          return_state = True)\n","        self.Fc = Dense(vi_vocab_size, activation = 'softmax')\n","        self.attention = attention\n","        \n","    def __call__(self, x, enc_outputs, states):\n","        x = tf.expand_dims(x, axis = 1)\n","        dec_embedding = self.Embedding(x)\n","        dec_outputs1 = self.LSTM_1(dec_embedding,\n","                                  initial_state = states[0])\n","        dec_outputs2 = self.LSTM_2(dec_outputs1[0],\n","                                   initial_state = states[1])\n","        \n","        dec_outputs = dec_outputs2[0]\n","        context, _ = self.attention(enc_outputs, dec_outputs)\n","        dec_concat = tf.concat([dec_outputs, context], axis = -1)\n","        final_concat = tf.reshape(dec_concat, (-1, dec_concat.shape[2]))\n","        \n","        final_outs = self.Fc(final_concat)\n","        dec_states = [dec_outputs1[1:], dec_outputs2[1:]]\n","        return final_outs, dec_states"]},{"cell_type":"markdown","metadata":{},"source":["* ### **Loss function**"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:58:41.310619Z","iopub.status.busy":"2023-02-16T11:58:41.310320Z","iopub.status.idle":"2023-02-16T11:58:41.319776Z","shell.execute_reply":"2023-02-16T11:58:41.318861Z","shell.execute_reply.started":"2023-02-16T11:58:41.310594Z"},"trusted":true},"outputs":[],"source":["class MaskedLoss(tf.keras.losses.Loss):\n","    def __init__(self):\n","        super(MaskedLoss, self).__init__()\n","        self.loss = SparseCategoricalCrossentropy(from_logits = True)\n","\n","    def __call__(self, y_true, y_pred):\n","        mask = 1 - np.equal(y_true, 0)\n","        loss = self.loss(y_true, y_pred)*mask\n","        return tf.reduce_mean(loss)"]},{"cell_type":"markdown","metadata":{},"source":["* ### **Evaluates the model after each epoch**"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:58:41.323994Z","iopub.status.busy":"2023-02-16T11:58:41.323034Z","iopub.status.idle":"2023-02-16T11:58:41.334350Z","shell.execute_reply":"2023-02-16T11:58:41.333764Z","shell.execute_reply.started":"2023-02-16T11:58:41.323957Z"},"trusted":true},"outputs":[],"source":["class Evaluate:\n","    def __init__(\n","    self,\n","    config,\n","    vi_utils\n","    ):\n","        self.config = config\n","        self.vi_utils = vi_utils\n","        \n","    def BLEU(self, y_pred, y_true):\n","        smoothing_function = SmoothingFunction()\n","        bleu_score = 100*corpus_bleu(list_of_references = [[seq] for seq in y_true],\n","                                     hypotheses = y_pred,\n","                                     smoothing_function = smoothing_function.method0)\n","        return round(bleu_score, 2)\n","    \n","    def remove(self, sequence):\n","        sentence = self.vi_utils.decode(sequence)\n","        new_sequence = [word for word in sentence.split(\" \") if word not in [self.config.pad_token,\n","                                                                             self.config.start_token,\n","                                                                             self.config.end_token]]\n","        return new_sequence\n","        \n","    def evaluation(self, encoder, decoder, dataset):\n","        y_true = []\n","        y_pred = []\n","        for x_test, Y_test in dataset.shuffle(buffer_size = 1, seed = 1).take(len(dataset)):\n","            X_test = tf.expand_dims(x_test, axis = 0)\n","            enc_outputs, last_states = encoder(X_test)\n","            dec_inputs = tf.constant([self.vi_utils.word_index[self.config.start_token]])\n","            sequence = []\n","            for _ in range(len(Y_test)):\n","                dec_outputs, last_states = decoder(dec_inputs, enc_outputs, last_states)\n","                pred_id = tf.argmax(dec_outputs, axis = 1).numpy()\n","                dec_inputs = pred_id\n","                sequence.append(pred_id[0])\n","            y_pred.append(self.remove(sequence))   \n","            y_true.append(self.remove(Y_test.numpy()))\n","            \n","        BLEU_score = self.BLEU(y_pred, y_true)\n","        return BLEU_score"]},{"cell_type":"markdown","metadata":{},"source":["* ### **Custom learning rate during training**"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:58:41.336460Z","iopub.status.busy":"2023-02-16T11:58:41.335931Z","iopub.status.idle":"2023-02-16T11:58:41.345968Z","shell.execute_reply":"2023-02-16T11:58:41.345314Z","shell.execute_reply.started":"2023-02-16T11:58:41.336407Z"},"trusted":true},"outputs":[],"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, initial_learning_rate, decay_rate, warmup_epoch):\n","        super(CustomSchedule, self).__init__()\n","        self.initial_learning_rate = initial_learning_rate\n","        self.decay_rate = decay_rate\n","        self.warmup_epoch = warmup_epoch\n","        \n","    def __call__(self, epoch):\n","        if epoch <= self.warmup_epoch:\n","            return self.initial_learning_rate\n","        else:\n","            return self.initial_learning_rate * (self.decay_rate**(epoch - self.warmup_epoch))\n","            "]},{"cell_type":"markdown","metadata":{},"source":["* ### **Custom training loop**"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:58:41.347737Z","iopub.status.busy":"2023-02-16T11:58:41.347193Z","iopub.status.idle":"2023-02-16T11:58:41.363180Z","shell.execute_reply":"2023-02-16T11:58:41.362338Z","shell.execute_reply.started":"2023-02-16T11:58:41.347703Z"},"trusted":true},"outputs":[],"source":["class Trainer:\n","    def __init__(\n","    self,\n","    encoder,\n","    decoder,\n","    config,\n","    train_ds,\n","    val_ds,\n","    test_ds,\n","    vi_utils,\n","    evaluate,\n","    maskedloss,\n","    lr_schedule,\n","    decay_rate = 0.5,\n","    warmup_epoch = 9,\n","    max_norm = 1.0\n","    ):\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.config = config\n","        self.train_ds = train_ds\n","        self.val_ds = val_ds\n","        self.test_ds = test_ds\n","        self.vi_utils = vi_utils\n","        self.evaluate = evaluate\n","        self.loss = maskedloss\n","        self.lr_schedule = lr_schedule(config.learning_rate, \n","                                       decay_rate, \n","                                       warmup_epoch)\n","        self.optimizer = Adam()\n","        self.max_norm = max_norm\n","        \n","    def training(self):\n","\n","        for epoch in range(self.config.epochs):\n","            start_time = time.time()\n","            total_loss = 0\n","            self.optimizer.lr.assign(self.lr_schedule(epoch))\n","            print('Current learning rate: ', self.optimizer.learning_rate.numpy())\n","\n","            for _, (x, y) in tqdm(enumerate(self.train_ds.take(len(self.train_ds)))):\n","                loss = 0\n","                with tf.GradientTape() as tape:\n","                    enc_outputs, last_states = self.encoder(x)\n","                    dec_inputs = tf.constant([self.vi_utils.word_index[self.config.start_token]]*len(x))\n","                    for i in range(1, y.shape[1]):\n","                        dec_outputs, last_states = self.decoder(dec_inputs, enc_outputs, last_states)\n","                        loss += self.loss(y[:, i], dec_outputs)\n","                        dec_inputs = y[:, i]\n","                    \n","                    train_vars = self.encoder.trainable_variables + self.decoder.trainable_variables\n","                    grads = tape.gradient(loss, train_vars)\n","                    clipped_grads, _ = tf.clip_by_global_norm(grads, self.max_norm)\n","                    self.optimizer.apply_gradients(zip(clipped_grads, train_vars))   \n","                    \n","                total_loss += loss\n","\n","            print(f'Epoch: {epoch + 1} -- Loss: {total_loss}')\n","            print('Time taken: %.2fs' % (time.time() - start_time))\n","            print('----------------------------------------------------------------')\n","        \n","        BLEU_2012 = self.evaluate.evaluation(self.encoder, self.decoder, self.val_ds)\n","        BLEU_2013 = self.evaluate.evaluation(self.encoder, self.decoder, self.test_ds)\n","        print()\n","        print('***************************************** END OF TRAINING *****************************************')\n","        print()\n","        print(f'BLEU score is calculated on test set 2012: {BLEU_2012}')\n","        print(f'BLEU score is calculated on test set 2013: {BLEU_2013}')"]},{"cell_type":"markdown","metadata":{},"source":["* ### **Parameter passing and training**"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:58:41.365194Z","iopub.status.busy":"2023-02-16T11:58:41.364608Z","iopub.status.idle":"2023-02-16T11:59:28.041691Z","shell.execute_reply":"2023-02-16T11:59:28.040503Z","shell.execute_reply.started":"2023-02-16T11:58:41.365158Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-02-16 11:59:23.302398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-16 11:59:23.380153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-16 11:59:23.381045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-16 11:59:23.384498: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-16 11:59:23.384875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-16 11:59:23.385682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-16 11:59:23.386369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-16 11:59:25.043768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-16 11:59:25.044609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-16 11:59:25.045314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-02-16 11:59:25.045919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"]},{"name":"stdout","output_type":"stream","text":["Shape of train source tensor:  (140274, 52)\n","Shape of train target tensor:  (140274, 52)\n","Shape of val source tensor:  (1591, 52)\n","Shape of val target tensor:  (1591, 52)\n","Shape of test source tensor:  (1338, 52)\n","Shape of test target tensor:  (1338, 52)\n","Batch number of training set:  548\n"]}],"source":["train_ds, val_ds, test_ds = Dataloader(en_utils,\n","                                       vi_utils,\n","                                       config).dataset()"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:59:28.043683Z","iopub.status.busy":"2023-02-16T11:59:28.043215Z","iopub.status.idle":"2023-02-16T11:59:28.095101Z","shell.execute_reply":"2023-02-16T11:59:28.093958Z","shell.execute_reply.started":"2023-02-16T11:59:28.043643Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["EN_VOCAB_SIZE:  17136\n","VI_VOCAB_SIZE:  7724\n"]}],"source":["en_vocab_size = len(en_utils.word_index)\n","vi_vocab_size = len(vi_utils.word_index)\n","\n","encoder = Encoder(config, en_vocab_size)\n","attention = Luong_Attention(config)\n","decoder = Decoder(config, attention, vi_vocab_size)\n","maskedloss = MaskedLoss()\n","evaluate = Evaluate(config, vi_utils)\n","\n","print('EN_VOCAB_SIZE: ', en_vocab_size)\n","print('VI_VOCAB_SIZE: ', vi_vocab_size)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:59:28.097264Z","iopub.status.busy":"2023-02-16T11:59:28.096871Z","iopub.status.idle":"2023-02-16T11:59:28.102550Z","shell.execute_reply":"2023-02-16T11:59:28.101493Z","shell.execute_reply.started":"2023-02-16T11:59:28.097227Z"},"trusted":true},"outputs":[],"source":["history = Trainer(encoder,\n","                  decoder,\n","                  config,\n","                  train_ds,\n","                  val_ds,\n","                  test_ds,\n","                  vi_utils,\n","                  evaluate,\n","                  maskedloss,\n","                  CustomSchedule)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T11:59:28.105170Z","iopub.status.busy":"2023-02-16T11:59:28.103961Z","iopub.status.idle":"2023-02-16T15:44:55.896221Z","shell.execute_reply":"2023-02-16T15:44:55.895125Z","shell.execute_reply.started":"2023-02-16T11:59:28.105143Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Current learning rate:  0.0008\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]2023-02-16 11:59:29.083994: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","/opt/conda/lib/python3.7/site-packages/keras/backend.py:4907: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n","548it [09:51,  1.08s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1 -- Loss: 52109.9140625\n","Time taken: 591.42s\n","----------------------------------------------------------------\n","Current learning rate:  0.0008\n"]},{"name":"stderr","output_type":"stream","text":["548it [09:54,  1.08s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2 -- Loss: 37052.95703125\n","Time taken: 594.43s\n","----------------------------------------------------------------\n","Current learning rate:  0.0008\n"]},{"name":"stderr","output_type":"stream","text":["548it [09:55,  1.09s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3 -- Loss: 30261.12109375\n","Time taken: 621.97s\n","----------------------------------------------------------------\n","Current learning rate:  0.0008\n"]},{"name":"stderr","output_type":"stream","text":["548it [09:54,  1.08s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4 -- Loss: 26543.806640625\n","Time taken: 621.96s\n","----------------------------------------------------------------\n","Current learning rate:  0.0008\n"]},{"name":"stderr","output_type":"stream","text":["548it [09:55,  1.09s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5 -- Loss: 24086.595703125\n","Time taken: 595.93s\n","----------------------------------------------------------------\n","Current learning rate:  0.0008\n"]},{"name":"stderr","output_type":"stream","text":["548it [09:56,  1.09s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 6 -- Loss: 22326.26953125\n","Time taken: 621.97s\n","----------------------------------------------------------------\n","Current learning rate:  0.0008\n"]},{"name":"stderr","output_type":"stream","text":["548it [09:57,  1.09s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 7 -- Loss: 20985.15625\n","Time taken: 621.95s\n","----------------------------------------------------------------\n","Current learning rate:  0.0008\n"]},{"name":"stderr","output_type":"stream","text":["548it [09:57,  1.09s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 8 -- Loss: 19903.208984375\n","Time taken: 597.52s\n","----------------------------------------------------------------\n","Current learning rate:  0.0008\n"]},{"name":"stderr","output_type":"stream","text":["548it [10:00,  1.10s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 9 -- Loss: 18982.298828125\n","Time taken: 621.94s\n","----------------------------------------------------------------\n","Current learning rate:  0.0008\n"]},{"name":"stderr","output_type":"stream","text":["548it [09:57,  1.09s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 10 -- Loss: 18162.23046875\n","Time taken: 597.50s\n","----------------------------------------------------------------\n","Current learning rate:  0.0004\n"]},{"name":"stderr","output_type":"stream","text":["548it [10:00,  1.10s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 11 -- Loss: 16886.11328125\n","Time taken: 621.95s\n","----------------------------------------------------------------\n","Current learning rate:  0.0002\n"]},{"name":"stderr","output_type":"stream","text":["548it [10:08,  1.11s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 12 -- Loss: 15947.720703125\n","Time taken: 608.13s\n","----------------------------------------------------------------\n","Current learning rate:  1e-04\n"]},{"name":"stderr","output_type":"stream","text":["548it [10:20,  1.13s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 13 -- Loss: 15402.076171875\n","Time taken: 620.14s\n","----------------------------------------------------------------\n","Current learning rate:  5e-05\n"]},{"name":"stderr","output_type":"stream","text":["548it [10:09,  1.11s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 14 -- Loss: 15105.5634765625\n","Time taken: 621.95s\n","----------------------------------------------------------------\n","Current learning rate:  2.5e-05\n"]},{"name":"stderr","output_type":"stream","text":["548it [10:12,  1.12s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 15 -- Loss: 14954.203125\n","Time taken: 621.96s\n","----------------------------------------------------------------\n","Current learning rate:  1.25e-05\n"]},{"name":"stderr","output_type":"stream","text":["548it [10:14,  1.12s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 16 -- Loss: 14878.4814453125\n","Time taken: 614.97s\n","----------------------------------------------------------------\n","Current learning rate:  6.25e-06\n"]},{"name":"stderr","output_type":"stream","text":["548it [10:16,  1.12s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 17 -- Loss: 14840.34765625\n","Time taken: 621.96s\n","----------------------------------------------------------------\n","Current learning rate:  3.125e-06\n"]},{"name":"stderr","output_type":"stream","text":["548it [10:17,  1.13s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 18 -- Loss: 14817.6591796875\n","Time taken: 621.97s\n","----------------------------------------------------------------\n","Current learning rate:  1.5625e-06\n"]},{"name":"stderr","output_type":"stream","text":["548it [10:20,  1.13s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 19 -- Loss: 14804.1142578125\n","Time taken: 620.21s\n","----------------------------------------------------------------\n","Current learning rate:  7.8125e-07\n"]},{"name":"stderr","output_type":"stream","text":["548it [10:17,  1.13s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 20 -- Loss: 14796.556640625\n","Time taken: 617.71s\n","----------------------------------------------------------------\n","\n","***************************************** END OF TRAINING *****************************************\n","\n","BLEU score is calculated on test set 2012: 22.21\n","BLEU score is calculated on test set 2013: 24.15\n"]}],"source":["history.training()"]},{"cell_type":"markdown","metadata":{},"source":["* ### **Inference**"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T15:44:55.898488Z","iopub.status.busy":"2023-02-16T15:44:55.897911Z","iopub.status.idle":"2023-02-16T15:44:55.910829Z","shell.execute_reply":"2023-02-16T15:44:55.909756Z","shell.execute_reply.started":"2023-02-16T15:44:55.898448Z"},"trusted":true},"outputs":[],"source":["class Translation:\n","    def __init__(self,\n","                encoder,\n","                decoder,\n","                en_utils,\n","                vi_utils,\n","                config):\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.en_utils = en_utils\n","        self.vi_utils = vi_utils\n","        self.config = config\n","        \n","    def predict(self, input_sentence, redundant_max_len = 10):\n","        sequence = []\n","        input_sequence = self.en_utils.add_border(self.en_utils.encode(input_sentence))\n","        max_len = len(input_sequence) + redundant_max_len\n","        \n","        X_test = tf.expand_dims(input_sequence, axis = 0)\n","        enc_outputs, last_states = self.encoder(X_test)\n","        dec_inputs = tf.constant([self.vi_utils.word_index[self.config.start_token]])\n","        for _ in range(max_len):\n","            start_time = time.time()\n","            dec_outputs, last_states = self.decoder(dec_inputs, enc_outputs, last_states)\n","            pred_id = tf.argmax(dec_outputs, axis = 1).numpy()\n","            dec_inputs = pred_id\n","            sequence.append(pred_id[0])\n","            if pred_id[0] == self.vi_utils.word_index[self.config.end_token]:\n","                break\n","        translated = self.vi_utils.decode(sequence)\n","        translated_sentence = \" \".join([word for word in translated.split(\" \") if word not in [self.config.pad_token,\n","                                                                                               self.config.start_token,\n","                                                                                               self.config.end_token]])\n","            \n","            \n","        print(f'Input sentence: {input_sentence}')\n","        print(f'Translated sentence: {translated_sentence}')\n","        print('Translation time: %.2fs' % (time.time() - start_time))"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T15:44:55.912842Z","iopub.status.busy":"2023-02-16T15:44:55.912473Z","iopub.status.idle":"2023-02-16T15:44:55.924153Z","shell.execute_reply":"2023-02-16T15:44:55.922736Z","shell.execute_reply.started":"2023-02-16T15:44:55.912798Z"},"trusted":true},"outputs":[],"source":["translation = Translation(encoder,\n","                          decoder,\n","                          en_utils,\n","                          vi_utils,\n","                          config)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T15:44:55.926455Z","iopub.status.busy":"2023-02-16T15:44:55.925771Z","iopub.status.idle":"2023-02-16T15:44:55.994368Z","shell.execute_reply":"2023-02-16T15:44:55.993337Z","shell.execute_reply.started":"2023-02-16T15:44:55.926399Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input sentence: What is your name?\n","Translated sentence: Tên anh là gì ?\n","Translation time: 0.01s\n"]}],"source":["input_sentence = 'What is your name?'\n","translation.predict(input_sentence)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T15:44:55.996379Z","iopub.status.busy":"2023-02-16T15:44:55.996016Z","iopub.status.idle":"2023-02-16T15:44:56.170567Z","shell.execute_reply":"2023-02-16T15:44:56.169503Z","shell.execute_reply.started":"2023-02-16T15:44:55.996341Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input sentence: They had been dancing for an hour when there was a knock on the door\n","Translated sentence: Họ đã nhảy múa trong một giờ khi đó có một con gián ở cửa hàng .\n","Translation time: 0.01s\n"]}],"source":["input_sentence = \"They had been dancing for an hour when there was a knock on the door\"\n","translation.predict(input_sentence)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T15:44:56.172680Z","iopub.status.busy":"2023-02-16T15:44:56.172271Z","iopub.status.idle":"2023-02-16T15:44:56.293232Z","shell.execute_reply":"2023-02-16T15:44:56.292130Z","shell.execute_reply.started":"2023-02-16T15:44:56.172641Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input sentence: I hope this project of mine will be successful\n","Translated sentence: Tôi hy vọng rằng dự án này sẽ thành công .\n","Translation time: 0.01s\n"]}],"source":["input_sentence = \"I hope this project of mine will be successful\"\n","translation.predict(input_sentence)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T15:44:56.295484Z","iopub.status.busy":"2023-02-16T15:44:56.294835Z","iopub.status.idle":"2023-02-16T15:44:56.388919Z","shell.execute_reply":"2023-02-16T15:44:56.387908Z","shell.execute_reply.started":"2023-02-16T15:44:56.295441Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input sentence: mathematics is the foundation of machine learning\n","Translated sentence: toán là nền tảng của việc học tập\n","Translation time: 0.01s\n"]}],"source":["input_sentence = 'mathematics is the foundation of machine learning'\n","translation.predict(input_sentence)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T15:44:56.390907Z","iopub.status.busy":"2023-02-16T15:44:56.390561Z","iopub.status.idle":"2023-02-16T15:44:56.480742Z","shell.execute_reply":"2023-02-16T15:44:56.479745Z","shell.execute_reply.started":"2023-02-16T15:44:56.390872Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input sentence: Be quiet for a moment.\n","Translated sentence: Hãy yên lặng trong một thời điểm .\n","Translation time: 0.01s\n"]}],"source":["input_sentence = 'Be quiet for a moment.'\n","translation.predict(input_sentence)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T15:44:56.486487Z","iopub.status.busy":"2023-02-16T15:44:56.486195Z","iopub.status.idle":"2023-02-16T15:44:56.611460Z","shell.execute_reply":"2023-02-16T15:44:56.610358Z","shell.execute_reply.started":"2023-02-16T15:44:56.486460Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input sentence: The police appealed to the crowd not to panic\n","Translated sentence: Cảnh sát đã thu hút đám đông không phải là hoang mang .\n","Translation time: 0.01s\n"]}],"source":["input_sentence = \"The police appealed to the crowd not to panic\"\n","translation.predict(input_sentence)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T15:44:56.613708Z","iopub.status.busy":"2023-02-16T15:44:56.613329Z","iopub.status.idle":"2023-02-16T15:44:56.726186Z","shell.execute_reply":"2023-02-16T15:44:56.725114Z","shell.execute_reply.started":"2023-02-16T15:44:56.613672Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input sentence: You have made the very same mistake again\n","Translated sentence: Bạn đã làm ra một sai lầm rất giống nhau .\n","Translation time: 0.01s\n"]}],"source":["input_sentence = \"You have made the very same mistake again\"\n","translation.predict(input_sentence)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T15:44:56.728186Z","iopub.status.busy":"2023-02-16T15:44:56.727831Z","iopub.status.idle":"2023-02-16T15:44:56.858972Z","shell.execute_reply":"2023-02-16T15:44:56.857883Z","shell.execute_reply.started":"2023-02-16T15:44:56.728151Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input sentence: This is the mildest winter that we have ever experienced\n","Translated sentence: Đây là mùa đông <unk> mà chúng ta đã từng trải qua .\n","Translation time: 0.01s\n"]}],"source":["input_sentence = \"This is the mildest winter that we have ever experienced\"\n","translation.predict(input_sentence)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T15:44:56.861042Z","iopub.status.busy":"2023-02-16T15:44:56.860669Z","iopub.status.idle":"2023-02-16T15:44:56.973771Z","shell.execute_reply":"2023-02-16T15:44:56.972722Z","shell.execute_reply.started":"2023-02-16T15:44:56.861004Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input sentence: Would you mind staying home and taking care of the children?\n","Translated sentence: Bạn có phiền ở nhà và chăm sóc trẻ em ?\n","Translation time: 0.01s\n"]}],"source":["input_sentence = \"Would you mind staying home and taking care of the children?\"\n","translation.predict(input_sentence)"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T15:44:56.976296Z","iopub.status.busy":"2023-02-16T15:44:56.975588Z","iopub.status.idle":"2023-02-16T15:44:57.181169Z","shell.execute_reply":"2023-02-16T15:44:57.180098Z","shell.execute_reply.started":"2023-02-16T15:44:56.976254Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input sentence: Unless it's something fairly impressive, I won't remember it\n","Translated sentence: Trừ khi nó gợi ra một cái gì đó khá ấn tượng , tôi đã đoạt giải nhớ rằng nó là một phần nhỏ\n","Translation time: 0.01s\n"]}],"source":["input_sentence = \"Unless it's something fairly impressive, I won't remember it\"\n","translation.predict(input_sentence)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T15:44:57.183494Z","iopub.status.busy":"2023-02-16T15:44:57.182559Z","iopub.status.idle":"2023-02-16T15:44:57.319171Z","shell.execute_reply":"2023-02-16T15:44:57.318118Z","shell.execute_reply.started":"2023-02-16T15:44:57.183449Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input sentence: You can get to her house in a variety of different ways\n","Translated sentence: Bạn có thể đến nhà mình ở một loạt những cách khác nhau .\n","Translation time: 0.01s\n"]}],"source":["input_sentence = \"You can get to her house in a variety of different ways\"\n","translation.predict(input_sentence)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T15:44:57.321097Z","iopub.status.busy":"2023-02-16T15:44:57.320649Z","iopub.status.idle":"2023-02-16T15:44:57.422678Z","shell.execute_reply":"2023-02-16T15:44:57.421677Z","shell.execute_reply.started":"2023-02-16T15:44:57.321061Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input sentence: I always end up looking up the same words in the dictionary\n","Translated sentence: Tôi luôn luôn luôn nhìn lại từ điển hình .\n","Translation time: 0.01s\n"]}],"source":["input_sentence = \"I always end up looking up the same words in the dictionary\"\n","translation.predict(input_sentence)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T15:44:57.424726Z","iopub.status.busy":"2023-02-16T15:44:57.424154Z","iopub.status.idle":"2023-02-16T15:44:57.571252Z","shell.execute_reply":"2023-02-16T15:44:57.570173Z","shell.execute_reply.started":"2023-02-16T15:44:57.424689Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input sentence: I want you to return it to me as soon as possible.\n","Translated sentence: Tôi muốn các bạn quay trở lại với tôi ngay sau khi có thể .\n","Translation time: 0.01s\n"]}],"source":["input_sentence = \"I want you to return it to me as soon as possible.\"\n","translation.predict(input_sentence)"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T15:44:57.573668Z","iopub.status.busy":"2023-02-16T15:44:57.572626Z","iopub.status.idle":"2023-02-16T15:44:57.725997Z","shell.execute_reply":"2023-02-16T15:44:57.724957Z","shell.execute_reply.started":"2023-02-16T15:44:57.573628Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input sentence: The company asked the bank to loan them some money to buy new machinery\n","Translated sentence: Công ty yêu cầu tiền cho họ một số tiền để mua máy móc mới .\n","Translation time: 0.01s\n"]}],"source":["input_sentence = \"The company asked the bank to loan them some money to buy new machinery\"\n","translation.predict(input_sentence)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-02-16T15:44:57.729238Z","iopub.status.busy":"2023-02-16T15:44:57.728613Z","iopub.status.idle":"2023-02-16T15:44:57.869458Z","shell.execute_reply":"2023-02-16T15:44:57.868372Z","shell.execute_reply.started":"2023-02-16T15:44:57.729200Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input sentence: Just have passion and really try, the whole universe will help you\n","Translated sentence: Chỉ có đam mê và thử , toàn bộ vũ trụ sẽ giúp bạn .\n","Translation time: 0.01s\n"]}],"source":["input_sentence = \"Just have passion and really try, the whole universe will help you\"\n","translation.predict(input_sentence)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
